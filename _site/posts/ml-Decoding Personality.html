<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.52">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krishna Kumar Shrestha">
<meta name="dcterms.date" content="2025-07-12">

<title>Decision Trees: A Complete Guide for Beginners – Actuarial-Reflections</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LSZ7YTNKVY"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LSZ7YTNKVY', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Actuarial-Reflections</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../all-blogs.html"> 
<span class="menu-text">All Blog Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/IKSHRESTHA"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ikshrestha/"> <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#decision-trees-a-complete-guide-for-beginners" id="toc-decision-trees-a-complete-guide-for-beginners" class="nav-link active" data-scroll-target="#decision-trees-a-complete-guide-for-beginners">Decision Trees: A Complete Guide for Beginners</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#what-is-a-decision-tree" id="toc-what-is-a-decision-tree" class="nav-link" data-scroll-target="#what-is-a-decision-tree">What is a Decision Tree?</a></li>
  <li><a href="#key-terms-in-decision-trees" id="toc-key-terms-in-decision-trees" class="nav-link" data-scroll-target="#key-terms-in-decision-trees">Key Terms in Decision Trees</a></li>
  <li><a href="#types-of-decision-trees-classification-vs.-regression" id="toc-types-of-decision-trees-classification-vs.-regression" class="nav-link" data-scroll-target="#types-of-decision-trees-classification-vs.-regression">Types of Decision Trees: Classification vs.&nbsp;Regression</a>
  <ul class="collapse">
  <li><a href="#classification-trees-categorical-output" id="toc-classification-trees-categorical-output" class="nav-link" data-scroll-target="#classification-trees-categorical-output">1. Classification Trees (Categorical Output)</a></li>
  <li><a href="#regression-trees-quantitative-output" id="toc-regression-trees-quantitative-output" class="nav-link" data-scroll-target="#regression-trees-quantitative-output">2. Regression Trees (Quantitative Output)</a></li>
  </ul></li>
  <li><a href="#advantages-and-limitations-of-decision-trees" id="toc-advantages-and-limitations-of-decision-trees" class="nav-link" data-scroll-target="#advantages-and-limitations-of-decision-trees">Advantages and Limitations of Decision Trees</a></li>
  <li><a href="#step-by-step-example-building-a-decision-tree-to-predict-personality-type" id="toc-step-by-step-example-building-a-decision-tree-to-predict-personality-type" class="nav-link" data-scroll-target="#step-by-step-example-building-a-decision-tree-to-predict-personality-type">Step-by-Step Example: Building a Decision Tree to Predict Personality Type</a>
  <ul class="collapse">
  <li><a href="#reading-and-inspecting-the-data" id="toc-reading-and-inspecting-the-data" class="nav-link" data-scroll-target="#reading-and-inspecting-the-data">1. Reading and Inspecting the Data</a></li>
  <li><a href="#preparing-the-data" id="toc-preparing-the-data" class="nav-link" data-scroll-target="#preparing-the-data">2. Preparing the Data</a></li>
  <li><a href="#splitting-the-data-traintest-split" id="toc-splitting-the-data-traintest-split" class="nav-link" data-scroll-target="#splitting-the-data-traintest-split">3. Splitting the Data: Train/Test Split</a></li>
  <li><a href="#building-the-decision-tree" id="toc-building-the-decision-tree" class="nav-link" data-scroll-target="#building-the-decision-tree">4. Building the Decision Tree</a></li>
  <li><a href="#evaluating-the-model" id="toc-evaluating-the-model" class="nav-link" data-scroll-target="#evaluating-the-model">5. Evaluating the Model</a></li>
  <li><a href="#pruning-the-tree" id="toc-pruning-the-tree" class="nav-link" data-scroll-target="#pruning-the-tree">6. Pruning the Tree</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#advanced-tree-methods-bagging-random-forest-and-boosting" id="toc-advanced-tree-methods-bagging-random-forest-and-boosting" class="nav-link" data-scroll-target="#advanced-tree-methods-bagging-random-forest-and-boosting">Advanced Tree Methods: Bagging, Random Forest, and Boosting</a>
  <ul class="collapse">
  <li><a href="#bagging-bootstrap-aggregating" id="toc-bagging-bootstrap-aggregating" class="nav-link" data-scroll-target="#bagging-bootstrap-aggregating">Bagging (Bootstrap Aggregating)</a></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a></li>
  <li><a href="#boosting" id="toc-boosting" class="nav-link" data-scroll-target="#boosting">Boosting</a></li>
  <li><a href="#key-differences" id="toc-key-differences" class="nav-link" data-scroll-target="#key-differences">Key Differences</a></li>
  <li><a href="#when-to-use-each-method" id="toc-when-to-use-each-method" class="nav-link" data-scroll-target="#when-to-use-each-method">When to Use Each Method</a></li>
  </ul></li>
  <li><a href="#step-by-step-bagging-random-forest-and-boosting-with-r" id="toc-step-by-step-bagging-random-forest-and-boosting-with-r" class="nav-link" data-scroll-target="#step-by-step-bagging-random-forest-and-boosting-with-r">Step-by-Step: Bagging, Random Forest, and Boosting with R</a>
  <ul class="collapse">
  <li><a href="#bagging-bootstrap-aggregating-1" id="toc-bagging-bootstrap-aggregating-1" class="nav-link" data-scroll-target="#bagging-bootstrap-aggregating-1">1. Bagging (Bootstrap Aggregating)</a></li>
  <li><a href="#random-forest-1" id="toc-random-forest-1" class="nav-link" data-scroll-target="#random-forest-1">2. Random Forest</a></li>
  <li><a href="#boosting-gradient-boosting-machine" id="toc-boosting-gradient-boosting-machine" class="nav-link" data-scroll-target="#boosting-gradient-boosting-machine">3. Boosting (Gradient Boosting Machine)</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Decision Trees: A Complete Guide for Beginners</h1>
  <div class="quarto-categories">
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">decision trees</div>
    <div class="quarto-category">classification</div>
    <div class="quarto-category">regression</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Krishna Kumar Shrestha </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 12, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="decision-trees-a-complete-guide-for-beginners" class="level1">
<h1>Decision Trees: A Complete Guide for Beginners</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Decision trees are one of the most intuitive and powerful tools in machine learning and data science. They mimic the way humans make decisions: by asking a series of questions and following the answers down different paths. In this article, we’ll break down what decision trees are, define the most important terms, explore the different types of decision trees based on the kind of output they produce, and explain the key metrics used to evaluate them. By the end, you’ll have a clear understanding of how decision trees work and how to use them for both classification and regression problems.</p>
</section>
<section id="what-is-a-decision-tree" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-decision-tree">What is a Decision Tree?</h2>
<p>A decision tree is a flowchart-like structure used to make decisions or predictions. Each internal node of the tree represents a test or question about a feature (for example, “Is age &gt; 30?”), each branch represents the outcome of the test, and each leaf node represents a final decision or prediction. Decision trees can be used for both classification (predicting categories) and regression (predicting numbers).</p>
<p>Imagine you want to decide whether to play tennis based on the weather. A decision tree might first ask, “Is it sunny?” If yes, it might then ask, “Is the humidity high?” and so on, until it reaches a decision like “Play” or “Don’t play.”</p>
</section>
<section id="key-terms-in-decision-trees" class="level2">
<h2 class="anchored" data-anchor-id="key-terms-in-decision-trees">Key Terms in Decision Trees</h2>
<p>Before we dive deeper, let’s define some important terms:</p>
<ul>
<li><strong>Root Node:</strong> The top node of the tree, where the first split or question is made.</li>
<li><strong>Internal Node:</strong> Any node that splits into further branches (not a leaf).</li>
<li><strong>Leaf Node (Terminal Node):</strong> The end node that gives the final output (class or value).</li>
<li><strong>Branch:</strong> A path from one node to another, representing the outcome of a test.</li>
<li><strong>Split:</strong> The process of dividing a node into two or more sub-nodes based on a feature.</li>
<li><strong>Feature (Attribute):</strong> A variable or column in your dataset used to split the data.</li>
<li><strong>Depth:</strong> The number of levels in the tree from the root to the deepest leaf.</li>
</ul>
</section>
<section id="types-of-decision-trees-classification-vs.-regression" class="level2">
<h2 class="anchored" data-anchor-id="types-of-decision-trees-classification-vs.-regression">Types of Decision Trees: Classification vs.&nbsp;Regression</h2>
<p>Decision trees are divided into two main types, depending on the nature of the output variable:</p>
<section id="classification-trees-categorical-output" class="level3">
<h3 class="anchored" data-anchor-id="classification-trees-categorical-output">1. Classification Trees (Categorical Output)</h3>
<p>Classification trees are used when the target variable is categorical—that is, when you want to predict a class or label (such as “spam” vs.&nbsp;“not spam,” or “disease” vs.&nbsp;“no disease”). At each node, the tree asks a question that splits the data into groups that are more homogeneous with respect to the target class.</p>
<p><strong>Example:</strong> Suppose you want to predict whether a loan applicant will default (“Yes” or “No”). The tree might split on features like income, credit score, or employment status, eventually leading to a prediction at the leaf node.</p>
<section id="key-metrics-for-classification-trees" class="level4">
<h4 class="anchored" data-anchor-id="key-metrics-for-classification-trees">Key Metrics for Classification Trees</h4>
<p>To decide the best way to split the data at each node, classification trees use metrics that measure how “pure” or homogeneous the resulting groups are. The most common metrics are:</p>
<ul>
<li><strong>Gini Impurity:</strong> Measures how often a randomly chosen element would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the node. Lower Gini means purer nodes.</li>
<li><strong>Entropy (Information Gain):</strong> Measures the amount of disorder or uncertainty. Splits that reduce entropy the most are preferred.</li>
</ul>
<p><strong>How to choose splits:</strong> At each node, the algorithm tries all possible splits and chooses the one that results in the greatest reduction in impurity (Gini or Entropy).</p>
<p><strong>Evaluation Metrics:</strong> After building the tree, we evaluate its performance using metrics such as: * <strong>Accuracy:</strong> The proportion of correct predictions. * <strong>Precision, Recall, F1 Score:</strong> Useful for imbalanced datasets. * <strong>Confusion Matrix:</strong> Shows the counts of true positives, false positives, etc.</p>
</section>
</section>
<section id="regression-trees-quantitative-output" class="level3">
<h3 class="anchored" data-anchor-id="regression-trees-quantitative-output">2. Regression Trees (Quantitative Output)</h3>
<p>Regression trees are used when the target variable is continuous or numerical (such as predicting house prices or temperatures). Instead of predicting a class, the tree predicts a number.</p>
<p><strong>Example:</strong> Suppose you want to predict the price of a house based on features like size, location, and number of bedrooms. The regression tree splits the data at each node to minimize the difference between the predicted and actual values.</p>
<section id="key-metrics-for-regression-trees" class="level4">
<h4 class="anchored" data-anchor-id="key-metrics-for-regression-trees">Key Metrics for Regression Trees</h4>
<p>To choose the best splits, regression trees use metrics that measure how well the split reduces the variability of the target variable. The most common metrics are:</p>
<ul>
<li><strong>Mean Squared Error (MSE):</strong> The average of the squared differences between predicted and actual values.</li>
<li><strong>Mean Absolute Error (MAE):</strong> The average of the absolute differences between predicted and actual values.</li>
</ul>
<p><strong>How to choose splits:</strong> At each node, the algorithm tries all possible splits and chooses the one that results in the greatest reduction in error (MSE or MAE).</p>
<p><strong>Evaluation Metrics:</strong> After building the tree, we evaluate its performance using metrics such as: * <strong>R-squared (R²):</strong> Measures how well the model explains the variability of the target. * <strong>Root Mean Squared Error (RMSE):</strong> The square root of MSE, in the same units as the target.</p>
</section>
</section>
</section>
<section id="advantages-and-limitations-of-decision-trees" class="level2">
<h2 class="anchored" data-anchor-id="advantages-and-limitations-of-decision-trees">Advantages and Limitations of Decision Trees</h2>
<p><strong>Advantages:</strong></p>
<ul>
<li>Easy to understand and interpret.</li>
<li>Can handle both numerical and categorical data.</li>
<li>Require little data preparation.</li>
<li>Can model non-linear relationships.</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li>Prone to overfitting (creating trees that are too complex and fit the training data too closely).</li>
<li>Can be unstable—small changes in data can lead to different trees.</li>
<li>Less accurate than some other algorithms (like random forests or boosting) on complex problems.</li>
</ul>
</section>
<section id="step-by-step-example-building-a-decision-tree-to-predict-personality-type" class="level2">
<h2 class="anchored" data-anchor-id="step-by-step-example-building-a-decision-tree-to-predict-personality-type">Step-by-Step Example: Building a Decision Tree to Predict Personality Type</h2>
<p>Let’s walk through a practical example using R, where we predict whether a person is an introvert or extrovert using a decision tree. We’ll cover every step: reading the data, cleaning it, splitting into training and test sets, building the tree, evaluating it, and pruning for better performance.</p>
<section id="reading-and-inspecting-the-data" class="level3">
<h3 class="anchored" data-anchor-id="reading-and-inspecting-the-data">1. Reading and Inspecting the Data</h3>
<p>First, we load the necessary libraries and read the dataset directly from the provided URL. We’ll use Quarto chunk options to suppress warnings and messages for a cleaner output.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(janitor)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret) <span class="co"># for train/test split</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the data</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://raw.githubusercontent.com/IKSHRESTHA/Actuarial-Reflections/refs/heads/main/data/06272925/personality_datasert.csv"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">clean_names</span>()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the data</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>spc_tbl_ [2,900 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
 $ time_spent_alone         : num [1:2900] 4 9 9 0 3 1 4 2 10 0 ...
 $ stage_fear               : chr [1:2900] "No" "Yes" "Yes" "No" ...
 $ social_event_attendance  : num [1:2900] 4 0 1 6 9 7 9 8 1 8 ...
 $ going_outside            : num [1:2900] 6 0 2 7 4 5 3 4 3 6 ...
 $ drained_after_socializing: chr [1:2900] "No" "Yes" "Yes" "No" ...
 $ friends_circle_size      : num [1:2900] 13 0 5 14 8 6 7 7 0 13 ...
 $ post_frequency           : num [1:2900] 5 3 2 8 5 6 7 8 3 8 ...
 $ personality              : chr [1:2900] "Extrovert" "Introvert" "Introvert" "Extrovert" ...
 - attr(*, "spec")=
  .. cols(
  ..   Time_spent_Alone = col_double(),
  ..   Stage_fear = col_character(),
  ..   Social_event_attendance = col_double(),
  ..   Going_outside = col_double(),
  ..   Drained_after_socializing = col_character(),
  ..   Friends_circle_size = col_double(),
  ..   Post_frequency = col_double(),
  ..   Personality = col_character()
  .. )
 - attr(*, "problems")=&lt;externalptr&gt; </code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> time_spent_alone  stage_fear        social_event_attendance going_outside
 Min.   : 0.000   Length:2900        Min.   : 0.000          Min.   :0    
 1st Qu.: 2.000   Class :character   1st Qu.: 2.000          1st Qu.:1    
 Median : 4.000   Mode  :character   Median : 3.963          Median :3    
 Mean   : 4.506                      Mean   : 3.963          Mean   :3    
 3rd Qu.: 7.000                      3rd Qu.: 6.000          3rd Qu.:5    
 Max.   :11.000                      Max.   :10.000          Max.   :7    
 drained_after_socializing friends_circle_size post_frequency  
 Length:2900               Min.   : 0.000      Min.   : 0.000  
 Class :character          1st Qu.: 3.000      1st Qu.: 1.000  
 Mode  :character          Median : 5.000      Median : 3.000  
                           Mean   : 6.269      Mean   : 3.565  
                           3rd Qu.:10.000      3rd Qu.: 6.000  
                           Max.   :15.000      Max.   :10.000  
 personality       
 Length:2900       
 Class :character  
 Mode  :character  
                   
                   
                   </code></pre>
</div>
</div>
<p><em>The output above shows the structure and summary statistics of the dataset. You can see the variable types, ranges, and a quick overview of the data. This helps us understand what features are available and if there are any obvious data quality issues.</em></p>
</section>
<section id="preparing-the-data" class="level3">
<h3 class="anchored" data-anchor-id="preparing-the-data">2. Preparing the Data</h3>
<p>We’ll make sure the target variable (<code>personality</code>) is a factor, and check for missing values. We’ll also suppress warnings and messages in this chunk.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert target to factor</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>personality <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(df<span class="sc">$</span>personality)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colSums</span>(<span class="fu">is.na</span>(df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         time_spent_alone                stage_fear   social_event_attendance 
                        0                         0                         0 
            going_outside drained_after_socializing       friends_circle_size 
                        0                         0                         0 
           post_frequency               personality 
                        0                         0 </code></pre>
</div>
</div>
<p><em>The output will show the number of missing values in each column. If all values are zero, there are no missing data to worry about. If not, you may need to handle them before modeling.</em></p>
</section>
<section id="splitting-the-data-traintest-split" class="level3">
<h3 class="anchored" data-anchor-id="splitting-the-data-traintest-split">3. Splitting the Data: Train/Test Split</h3>
<p>We’ll split the data into 70% training and 30% testing sets to evaluate our model’s performance on unseen data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># for reproducibility</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(df<span class="sc">$</span>personality, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> df[train_index, ]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> df[<span class="sc">-</span>train_index, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>This step ensures that our model is trained on one portion of the data and tested on another, helping us assess how well it generalizes to new cases.</em></p>
</section>
<section id="building-the-decision-tree" class="level3">
<h3 class="anchored" data-anchor-id="building-the-decision-tree">4. Building the Decision Tree</h3>
<p>Now, we’ll build a classification tree to predict <code>personality</code> using all other variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>tree_model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(personality <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">method =</span> <span class="st">"class"</span>, <span class="at">cp =</span> <span class="fl">0.01</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the tree</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-Decoding-Personality_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><em>The plot above shows the structure of the decision tree. Each node represents a split based on a feature, and the leaves show the predicted class (introvert or extrovert).</em></p>
</section>
<section id="evaluating-the-model" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-the-model">5. Evaluating the Model</h3>
<p>We’ll use the test set to see how well our tree predicts introverts vs.&nbsp;extroverts.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_model, test_data, <span class="at">type =</span> <span class="st">"class"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred, test_data<span class="sc">$</span>personality)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

           Reference
Prediction  Extrovert Introvert
  Extrovert       412        29
  Introvert        35       393
                                          
               Accuracy : 0.9264          
                 95% CI : (0.9069, 0.9428)
    No Information Rate : 0.5144          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.8526          
                                          
 Mcnemar's Test P-Value : 0.532           
                                          
            Sensitivity : 0.9217          
            Specificity : 0.9313          
         Pos Pred Value : 0.9342          
         Neg Pred Value : 0.9182          
             Prevalence : 0.5144          
         Detection Rate : 0.4741          
   Detection Prevalence : 0.5075          
      Balanced Accuracy : 0.9265          
                                          
       'Positive' Class : Extrovert       
                                          </code></pre>
</div>
</div>
<p><em>The confusion matrix output will display the number of correct and incorrect predictions for each class. Accuracy, sensitivity, and specificity are also shown, helping you judge the model’s performance.</em></p>
</section>
<section id="pruning-the-tree" class="level3">
<h3 class="anchored" data-anchor-id="pruning-the-tree">6. Pruning the Tree</h3>
<p>Decision trees can overfit, so pruning helps simplify the tree and improve generalization. We’ll use the complexity parameter (cp) to prune.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find optimal cp value</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(tree_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Classification tree:
rpart(formula = personality ~ ., data = train_data, method = "class", 
    cp = 0.01)

Variables actually used in tree construction:
[1] drained_after_socializing stage_fear               

Root node error: 987/2031 = 0.48597

n= 2031 

        CP nsplit rel error  xerror     xstd
1 0.855117      0   1.00000 1.00000 0.022821
2 0.016211      1   0.14488 0.14488 0.011681
3 0.010000      2   0.12867 0.12969 0.011096</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose the cp with lowest cross-validated error</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>best_cp <span class="ot">&lt;-</span> tree_model<span class="sc">$</span>cptable[<span class="fu">which.min</span>(tree_model<span class="sc">$</span>cptable[,<span class="st">"xerror"</span>]), <span class="st">"CP"</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prune the tree</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>pruned_tree <span class="ot">&lt;-</span> <span class="fu">prune</span>(tree_model, <span class="at">cp =</span> best_cp)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize pruned tree</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(pruned_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-Decoding-Personality_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate pruned tree</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>pruned_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(pruned_tree, test_data, <span class="at">type =</span> <span class="st">"class"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pruned_pred, test_data<span class="sc">$</span>personality)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

           Reference
Prediction  Extrovert Introvert
  Extrovert       412        29
  Introvert        35       393
                                          
               Accuracy : 0.9264          
                 95% CI : (0.9069, 0.9428)
    No Information Rate : 0.5144          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.8526          
                                          
 Mcnemar's Test P-Value : 0.532           
                                          
            Sensitivity : 0.9217          
            Specificity : 0.9313          
         Pos Pred Value : 0.9342          
         Neg Pred Value : 0.9182          
             Prevalence : 0.5144          
         Detection Rate : 0.4741          
   Detection Prevalence : 0.5075          
      Balanced Accuracy : 0.9265          
                                          
       'Positive' Class : Extrovert       
                                          </code></pre>
</div>
</div>
<p><em>After pruning, the tree is simpler and less likely to overfit. The new confusion matrix shows how well the pruned tree performs on the test data. Compare this to the previous results to see if pruning improved generalization.</em></p>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>We loaded and cleaned the data (with warnings suppressed for clarity).</li>
<li>Split it into training and test sets.</li>
<li>Built and visualized a decision tree to predict personality type.</li>
<li>Evaluated its performance with a confusion matrix.</li>
<li>Pruned the tree and compared results.</li>
</ul>
<p>This step-by-step approach helps you understand not just how to build a decision tree, but also how to interpret the output and ensure it performs well on new, unseen data.</p>
</section>
</section>
<section id="advanced-tree-methods-bagging-random-forest-and-boosting" class="level2">
<h2 class="anchored" data-anchor-id="advanced-tree-methods-bagging-random-forest-and-boosting">Advanced Tree Methods: Bagging, Random Forest, and Boosting</h2>
<p>As powerful as decision trees are, they have some limitations—most notably, they can be unstable and prone to overfitting. To address these issues and achieve better predictive performance, data scientists use advanced ensemble methods that combine many trees. The three most popular are bagging, random forests, and boosting. Let’s explore each, their differences, and when to use them.</p>
<section id="bagging-bootstrap-aggregating" class="level3">
<h3 class="anchored" data-anchor-id="bagging-bootstrap-aggregating">Bagging (Bootstrap Aggregating)</h3>
<p>Bagging is short for “bootstrap aggregating.” The idea is simple: build many decision trees, each on a different random sample (with replacement) of the training data, and then average their predictions (for regression) or take a majority vote (for classification).</p>
<ul>
<li><strong>How it works:</strong>
<ul>
<li>Draw multiple bootstrap samples from the training data.</li>
<li>Train a separate decision tree on each sample.</li>
<li>For prediction, aggregate the results (average or majority vote).</li>
</ul></li>
<li><strong>Strengths:</strong>
<ul>
<li>Reduces variance and helps prevent overfitting.</li>
<li>Each tree is independent, so the method is easy to parallelize.</li>
</ul></li>
<li><strong>Limitations:</strong>
<ul>
<li>All features are considered at each split, so trees can be highly correlated if some features are very strong predictors.</li>
</ul></li>
</ul>
<p><strong>Example:</strong> Bagging is implemented in R with the <code>bagging()</code> function from the <code>ipred</code> package, or by setting <code>method = "treebag"</code> in the <code>caret</code> package.</p>
</section>
<section id="random-forest" class="level3">
<h3 class="anchored" data-anchor-id="random-forest">Random Forest</h3>
<p>Random forest is an extension of bagging that adds an extra layer of randomness. In addition to using bootstrap samples, random forest also selects a random subset of features at each split in the tree. This decorrelates the trees, making the ensemble even more robust.</p>
<ul>
<li><strong>How it works:</strong>
<ul>
<li>Like bagging, but at each split, only a random subset of features is considered.</li>
<li>This means each tree is more different from the others, reducing correlation.</li>
</ul></li>
<li><strong>Strengths:</strong>
<ul>
<li>Even lower variance and better generalization than bagging.</li>
<li>Handles large datasets and many features well.</li>
<li>Provides feature importance measures.</li>
</ul></li>
<li><strong>Limitations:</strong>
<ul>
<li>Less interpretable than a single tree.</li>
<li>Can be slower to train and predict with very large forests.</li>
</ul></li>
</ul>
<p><strong>Example:</strong> Random forest is implemented in R with the <code>randomForest</code> package or by setting <code>method = "rf"</code> in <code>caret</code>.</p>
</section>
<section id="boosting" class="level3">
<h3 class="anchored" data-anchor-id="boosting">Boosting</h3>
<p>Boosting is a different approach: instead of building trees independently, it builds them sequentially. Each new tree focuses on correcting the errors of the previous ones. The final prediction is a weighted combination of all trees.</p>
<ul>
<li><strong>How it works:</strong>
<ul>
<li>Trees are built one after another.</li>
<li>Each tree tries to fix the mistakes of the previous trees by giving more weight to misclassified points.</li>
<li>Predictions are combined (often by weighted sum or vote).</li>
</ul></li>
<li><strong>Strengths:</strong>
<ul>
<li>Can achieve very high accuracy.</li>
<li>Often outperforms bagging and random forest on complex problems.</li>
</ul></li>
<li><strong>Limitations:</strong>
<ul>
<li>More sensitive to noise and outliers.</li>
<li>Can overfit if not properly tuned.</li>
<li>Slower to train, as trees are built sequentially.</li>
</ul></li>
</ul>
<p><strong>Example:</strong> Popular boosting algorithms include AdaBoost (<code>adabag</code> package in R), Gradient Boosting Machines (<code>gbm</code> package), and XGBoost (<code>xgboost</code> package).</p>
</section>
<section id="key-differences" class="level3">
<h3 class="anchored" data-anchor-id="key-differences">Key Differences</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 10%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 22%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Trees Built</th>
<th>Feature Selection</th>
<th>Aggregation</th>
<th>Strengths</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bagging</td>
<td>Parallel</td>
<td>All features</td>
<td>Average/Vote</td>
<td>Reduces variance</td>
<td>Trees can be correlated</td>
</tr>
<tr class="even">
<td>Random Forest</td>
<td>Parallel</td>
<td>Random subset</td>
<td>Average/Vote</td>
<td>Lower variance, robust</td>
<td>Less interpretable</td>
</tr>
<tr class="odd">
<td>Boosting</td>
<td>Sequential</td>
<td>All or subset</td>
<td>Weighted sum/vote</td>
<td>High accuracy, flexible</td>
<td>Sensitive to noise, slower</td>
</tr>
</tbody>
</table>
</section>
<section id="when-to-use-each-method" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-each-method">When to Use Each Method</h3>
<ul>
<li><strong>Bagging:</strong> When you want a simple way to reduce variance and your trees are overfitting.</li>
<li><strong>Random Forest:</strong> When you want strong performance out-of-the-box, especially with many features or large datasets.</li>
<li><strong>Boosting:</strong> When you need the highest possible accuracy and are willing to tune parameters and accept longer training times.</li>
</ul>
<p>In practice, random forest is often the first ensemble method to try, as it balances accuracy, robustness, and ease of use. Boosting can deliver even better results, but requires more careful tuning.</p>
</section>
</section>
<section id="step-by-step-bagging-random-forest-and-boosting-with-r" class="level2">
<h2 class="anchored" data-anchor-id="step-by-step-bagging-random-forest-and-boosting-with-r">Step-by-Step: Bagging, Random Forest, and Boosting with R</h2>
<p>Let’s apply bagging, random forest, and boosting to the same personality dataset, following the same clear, step-by-step approach as before. We’ll use the <code>caret</code>, <code>randomForest</code>, and <code>gbm</code> packages for these examples. Make sure these packages are installed before running the code.</p>
<section id="bagging-bootstrap-aggregating-1" class="level3">
<h3 class="anchored" data-anchor-id="bagging-bootstrap-aggregating-1">1. Bagging (Bootstrap Aggregating)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ipred) <span class="co"># for bagging</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Bagging model</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>bag_model <span class="ot">&lt;-</span> <span class="fu">bagging</span>(personality <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">coob =</span> <span class="cn">TRUE</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>bag_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(bag_model, test_data, <span class="at">type =</span> <span class="st">"class"</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(bag_pred, test_data<span class="sc">$</span>personality)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

           Reference
Prediction  Extrovert Introvert
  Extrovert       407        39
  Introvert        40       383
                                         
               Accuracy : 0.9091         
                 95% CI : (0.888, 0.9274)
    No Information Rate : 0.5144         
    P-Value [Acc &gt; NIR] : &lt;2e-16         
                                         
                  Kappa : 0.818          
                                         
 Mcnemar's Test P-Value : 1              
                                         
            Sensitivity : 0.9105         
            Specificity : 0.9076         
         Pos Pred Value : 0.9126         
         Neg Pred Value : 0.9054         
             Prevalence : 0.5144         
         Detection Rate : 0.4684         
   Detection Prevalence : 0.5132         
      Balanced Accuracy : 0.9090         
                                         
       'Positive' Class : Extrovert      
                                         </code></pre>
</div>
</div>
<p><em>Bagging builds multiple trees on bootstrapped samples and aggregates their predictions. The confusion matrix shows the accuracy and class-wise performance of the bagged ensemble.</em></p>
</section>
<section id="random-forest-1" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-1">2. Random Forest</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest model</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(personality <span class="sc">~</span> ., <span class="at">data =</span> train_data, <span class="at">ntree =</span> <span class="dv">100</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>rf_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, test_data)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(rf_pred, test_data<span class="sc">$</span>personality)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

           Reference
Prediction  Extrovert Introvert
  Extrovert       412        28
  Introvert        35       394
                                          
               Accuracy : 0.9275          
                 95% CI : (0.9082, 0.9438)
    No Information Rate : 0.5144          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.855           
                                          
 Mcnemar's Test P-Value : 0.4497          
                                          
            Sensitivity : 0.9217          
            Specificity : 0.9336          
         Pos Pred Value : 0.9364          
         Neg Pred Value : 0.9184          
             Prevalence : 0.5144          
         Detection Rate : 0.4741          
   Detection Prevalence : 0.5063          
      Balanced Accuracy : 0.9277          
                                          
       'Positive' Class : Extrovert       
                                          </code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance plot</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-Decoding-Personality_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><em>Random forest builds many trees, each considering a random subset of features at each split. The confusion matrix shows the model’s performance, and the variable importance plot highlights which features are most influential.</em></p>
</section>
<section id="boosting-gradient-boosting-machine" class="level3">
<h3 class="anchored" data-anchor-id="boosting-gradient-boosting-machine">3. Boosting (Gradient Boosting Machine)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># For gbm, all predictors must be numeric, ordered, or factor.</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert character columns to factors in train and test data</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>train_data_gbm <span class="ot">&lt;-</span> train_data</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (col <span class="cf">in</span> <span class="fu">names</span>(train_data_gbm)) {</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.character</span>(train_data_gbm[[col]])) {</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    train_data_gbm[[col]] <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(train_data_gbm[[col]])</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>test_data_gbm <span class="ot">&lt;-</span> test_data</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (col <span class="cf">in</span> <span class="fu">names</span>(test_data_gbm)) {</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.character</span>(test_data_gbm[[col]])) {</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    test_data_gbm[[col]] <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(test_data_gbm[[col]])</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode personality as 0/1 for gbm</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>train_data_gbm<span class="sc">$</span>personality_num <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(train_data_gbm<span class="sc">$</span>personality <span class="sc">==</span> <span class="st">"Introvert"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>test_data_gbm<span class="sc">$</span>personality_num <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(test_data_gbm<span class="sc">$</span>personality <span class="sc">==</span> <span class="st">"Introvert"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GBM model (distribution = "bernoulli" for binary classification)</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>gbm_model <span class="ot">&lt;-</span> <span class="fu">gbm</span>(personality_num <span class="sc">~</span> . <span class="sc">-</span>personality, <span class="at">data =</span> train_data_gbm, <span class="at">distribution =</span> <span class="st">"bernoulli"</span>, <span class="at">n.trees =</span> <span class="dv">100</span>, <span class="at">interaction.depth =</span> <span class="dv">3</span>, <span class="at">shrinkage =</span> <span class="fl">0.05</span>, <span class="at">n.minobsinnode =</span> <span class="dv">10</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities and convert to class</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>gbm_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(gbm_model, test_data_gbm, <span class="at">n.trees =</span> <span class="dv">100</span>, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>gbm_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(gbm_probs <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Extrovert"</span>, <span class="st">"Introvert"</span>)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>gbm_pred <span class="ot">&lt;-</span> <span class="fu">factor</span>(gbm_pred, <span class="at">levels =</span> <span class="fu">levels</span>(test_data<span class="sc">$</span>personality))</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(gbm_pred, test_data<span class="sc">$</span>personality)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

           Reference
Prediction  Extrovert Introvert
  Extrovert       412        28
  Introvert        35       394
                                          
               Accuracy : 0.9275          
                 95% CI : (0.9082, 0.9438)
    No Information Rate : 0.5144          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.855           
                                          
 Mcnemar's Test P-Value : 0.4497          
                                          
            Sensitivity : 0.9217          
            Specificity : 0.9336          
         Pos Pred Value : 0.9364          
         Neg Pred Value : 0.9184          
             Prevalence : 0.5144          
         Detection Rate : 0.4741          
   Detection Prevalence : 0.5063          
      Balanced Accuracy : 0.9277          
                                          
       'Positive' Class : Extrovert       
                                          </code></pre>
</div>
</div>
<p><em>Boosting builds trees sequentially, each focusing on correcting the errors of the previous ones. The confusion matrix shows the boosted model’s performance. You can tune parameters like <code>n.trees</code> and <code>shrinkage</code> for better results.</em></p>
<hr>
<p><strong>Summary:</strong></p>
<ul>
<li>We applied bagging, random forest, and boosting to the same dataset.</li>
<li>Each method was evaluated using a confusion matrix for easy comparison.</li>
<li>Random forest also provides a feature importance plot to interpret which variables matter most.</li>
</ul>
<p>This hands-on approach helps you see the practical differences between these advanced tree ensemble methods and how to implement them in R.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>