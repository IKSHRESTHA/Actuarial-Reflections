[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Important\n\n\n\nOpen to Work:\nI am actively seeking opportunities in actuarial science roles in the USA. If you know of any positions or have networking leads, please feel free to reach out!\nHi, I‚Äôm Krishna Kumar Shrestha‚Äîan aspiring actuary passionate about using data, analytics, and technology to solve real-world problems in insurance and risk management.\nI am currently pursuing my Master of Science in Professional Science (Actuarial Science) at Middle Tennessee State University, maintaining a GPA of 3.92. My academic journey began in Nepal, where I earned my Bachelor of Mathematical Sciences (Actuarial Science) from Tribhuvan University. Along the way, I‚Äôve passed several Society of Actuaries (SOA) exams:\n‚úÖ Exam P\n‚úÖ Exam FM\n‚úÖ Exam FAM\n‚úÖ Exam ALTAM\n‚úÖ Exam SRM"
  },
  {
    "objectID": "about.html#professional-experience",
    "href": "about.html#professional-experience",
    "title": "About Me",
    "section": "Professional Experience",
    "text": "Professional Experience\nMy hands-on experience spans actuarial consulting, teaching, analytics, and insurtech. Currently, I serve as a:\nüë®‚Äçüè´ Graduate Teaching Assistant, MTSU (Present):\nSupporting actuarial coursework, instruction, mentoring, and applied problem-solving.\nüßÆ Senior Actuarial Analyst, Principal Risk Consulting:\nDeveloped pricing models for life insurance and led actuarial valuations under international accounting standards.\nüë®‚Äçüíª Assistant Lecturer, Tribhuvan University:\nTaught R programming and Excel for actuarial applications; contributed to curriculum development and accreditation.\nüöÄ Consultant, eBeema (Insurtech Startup):\nSupported digital insurance platform launches and enhanced user experiences.\nüìä Data Analyst Intern, Numeric Mind:\nWorked on real data projects early in my career."
  },
  {
    "objectID": "about.html#skills-certifications",
    "href": "about.html#skills-certifications",
    "title": "About Me",
    "section": "Skills & Certifications",
    "text": "Skills & Certifications\nüêç Programming: R, Python, Excel\nüìä Actuarial Modeling & Data Analytics\nüèÜ Certifications:\n- Data Analyst Professional (DataCamp)\n- Winner, IFoA R Number Modeling Hackathon (2021)\n- Finalist, Kislay Actuarial Hackathon (2020)"
  },
  {
    "objectID": "about.html#leadership-community",
    "href": "about.html#leadership-community",
    "title": "About Me",
    "section": "Leadership & Community",
    "text": "Leadership & Community\nü§ù Secretary, Actuarial Society of Nepal\nOrganized training, networking events, and knowledge-sharing for the actuarial community.\nüåê Collaborated with regulators and international bodies (SOA, IAA, UNDP) to support policy and actuarial growth in Nepal."
  },
  {
    "objectID": "about.html#my-approach",
    "href": "about.html#my-approach",
    "title": "About Me",
    "section": "My Approach",
    "text": "My Approach\nI believe actuarial science is not just about numbers‚Äîit‚Äôs about making a positive impact on people‚Äôs lives by quantifying risk and guiding decisions with integrity and insight. Whether building pricing models, teaching, or launching digital solutions, I bring curiosity, collaboration, and a commitment to professional excellence."
  },
  {
    "objectID": "about.html#lets-connect",
    "href": "about.html#lets-connect",
    "title": "About Me",
    "section": "Let‚Äôs Connect",
    "text": "Let‚Äôs Connect\n\nLinkedIn\nüìß krishnakumarshrestha00@gmail.com\n\n\nExplore my blog for reflections on actuarial topics, data science, and my professional journey from Nepal to the U.S. and beyond!"
  },
  {
    "objectID": "posts/ml-Decoding Personality.html",
    "href": "posts/ml-Decoding Personality.html",
    "title": "Decoding Personality: ML Models as Your Guide to Introverts vs.¬†Extroverts",
    "section": "",
    "text": "Welcome to the first installment in our series decoding the human personality through data science! Before we build predictive models in latter posts, we must answer a fundamental question: What do we really mean by introvert and extrovert - and how can data reveal their true behavioral patters?\nIn this article, we‚Äôll explore:\n\nWhy Exploratory Data Analysis (EDA) is your essential first step\nVisual storytelling with ggplot2 uncovers hidden patterns\n\n\n\n\n\nEDA helps us understand our variables.\nHelps us detect data Quality Issues ( Missing Values, Outliers )\nHelps us uncover hidden relationships\nHelp us Validate assumptions\nHelp us in feature engineering\n\nLets start now exploring the data. First thing First, we need to import library that we are going to use for this project:\nAfter loaing the library, we will read the data.\n\n\n\nThe data has been downloaded from the kaggle and you can find about the data more on here:\n\npersonality_dataset &lt;-readr::read_csv(\"https://raw.githubusercontent.com/IKSHRESTHA/Actuarial-Reflections/refs/heads/main/data/06272925/personality_datasert.csv\")\n\n`curl` package not installed, falling back to using `url()`\nRows: 2900 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): Stage_fear, Drained_after_socializing, Personality\ndbl (5): Time_spent_Alone, Social_event_attendance, Going_outside, Friends_c...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# cleaning the columns name \ndf &lt;- personality_dataset |&gt;\n  janitor::clean_names()\n\ncolnames(df)\n\n[1] \"time_spent_alone\"          \"stage_fear\"               \n[3] \"social_event_attendance\"   \"going_outside\"            \n[5] \"drained_after_socializing\" \"friends_circle_size\"      \n[7] \"post_frequency\"            \"personality\"              \n\n\n\nlibrary(extrafont)  # For font consistency\n\nRegistering fonts with R\n\ntheme_actuarial &lt;- function(base_size = 12, \n                            base_family = \"mono\",\n                            title_position = \"middle\",\n                            border_color = \"black\") {\n  \n  # Load monospaced font (install first if needed)\n  extrafont::loadfonts(quiet = TRUE)\n  \n  theme_minimal(base_size = base_size, base_family = base_family) %+replace%\n    theme(\n      # Text elements\n      text = element_text(family = base_family, color = \"black\"),\n      title = element_text(face = \"bold\", size = base_size * 1.2),\n      plot.title = element_text(\n        hjust = 0.5, \n        margin = margin(b = base_size),\n        size = base_size * 1.4\n      ),\n      plot.subtitle = element_text(\n        hjust = 0.5, \n        margin = margin(b = base_size)\n      ),\n      plot.caption = element_text(\n        hjust = 1, \n        size = base_size * 0.8,\n        color = \"grey40\"\n      ),\n      \n      # Axis elements\n      axis.title = element_text(\n        face = \"bold\", \n        color = \"black\",\n        size = base_size * 1.1\n      ),\n      axis.title.x = element_text(\n        margin = margin(t = base_size * 0.5),\n        hjust = title_position\n      ),\n      axis.title.y = element_text(\n        margin = margin(r = base_size * 0.5),\n        angle = 90,\n        hjust = title_position\n      ),\n      axis.text = element_text(color = \"grey30\"),\n      axis.line = element_line(\n        color = border_color, \n        linewidth = 0.8\n      ),\n      \n      # Panel elements\n      panel.grid.major = element_line(\n        color = \"grey92\", \n        linewidth = 0.3\n      ),\n      panel.grid.minor = element_blank(),\n      panel.background = element_rect(fill = \"white\", color = NA),\n      panel.border = element_blank(),\n      \n      # Legend elements\n      legend.title = element_text(face = \"bold\"),\n      legend.background = element_rect(fill = \"white\", color = NA),\n      legend.key = element_rect(fill = \"white\", color = NA),\n      \n      # Plot elements\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.margin = margin(base_size, base_size, base_size, base_size),\n      strip.background = element_rect(fill = \"grey95\", color = NA),\n      strip.text = element_text(face = \"bold\")\n    )\n}\n\n\n#df_summary=rstatix::get_summary_stats(df,type=\"full\")\n#df_summary"
  },
  {
    "objectID": "posts/ml-Decoding Personality.html#introduction",
    "href": "posts/ml-Decoding Personality.html#introduction",
    "title": "Decoding Personality: ML Models as Your Guide to Introverts vs.¬†Extroverts",
    "section": "",
    "text": "Welcome to the first installment in our series decoding the human personality through data science! Before we build predictive models in latter posts, we must answer a fundamental question: What do we really mean by introvert and extrovert - and how can data reveal their true behavioral patters?\nIn this article, we‚Äôll explore:\n\nWhy Exploratory Data Analysis (EDA) is your essential first step\nVisual storytelling with ggplot2 uncovers hidden patterns"
  },
  {
    "objectID": "posts/ml-Decoding Personality.html#why-eda",
    "href": "posts/ml-Decoding Personality.html#why-eda",
    "title": "Decoding Personality: ML Models as Your Guide to Introverts vs.¬†Extroverts",
    "section": "",
    "text": "EDA helps us understand our variables.\nHelps us detect data Quality Issues ( Missing Values, Outliers )\nHelps us uncover hidden relationships\nHelp us Validate assumptions\nHelp us in feature engineering\n\nLets start now exploring the data. First thing First, we need to import library that we are going to use for this project:\nAfter loaing the library, we will read the data."
  },
  {
    "objectID": "posts/ml-Decoding Personality.html#about-the-data",
    "href": "posts/ml-Decoding Personality.html#about-the-data",
    "title": "Decoding Personality: ML Models as Your Guide to Introverts vs.¬†Extroverts",
    "section": "",
    "text": "The data has been downloaded from the kaggle and you can find about the data more on here:\n\npersonality_dataset &lt;-readr::read_csv(\"https://raw.githubusercontent.com/IKSHRESTHA/Actuarial-Reflections/refs/heads/main/data/06272925/personality_datasert.csv\")\n\n`curl` package not installed, falling back to using `url()`\nRows: 2900 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): Stage_fear, Drained_after_socializing, Personality\ndbl (5): Time_spent_Alone, Social_event_attendance, Going_outside, Friends_c...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# cleaning the columns name \ndf &lt;- personality_dataset |&gt;\n  janitor::clean_names()\n\ncolnames(df)\n\n[1] \"time_spent_alone\"          \"stage_fear\"               \n[3] \"social_event_attendance\"   \"going_outside\"            \n[5] \"drained_after_socializing\" \"friends_circle_size\"      \n[7] \"post_frequency\"            \"personality\"              \n\n\n\nlibrary(extrafont)  # For font consistency\n\nRegistering fonts with R\n\ntheme_actuarial &lt;- function(base_size = 12, \n                            base_family = \"mono\",\n                            title_position = \"middle\",\n                            border_color = \"black\") {\n  \n  # Load monospaced font (install first if needed)\n  extrafont::loadfonts(quiet = TRUE)\n  \n  theme_minimal(base_size = base_size, base_family = base_family) %+replace%\n    theme(\n      # Text elements\n      text = element_text(family = base_family, color = \"black\"),\n      title = element_text(face = \"bold\", size = base_size * 1.2),\n      plot.title = element_text(\n        hjust = 0.5, \n        margin = margin(b = base_size),\n        size = base_size * 1.4\n      ),\n      plot.subtitle = element_text(\n        hjust = 0.5, \n        margin = margin(b = base_size)\n      ),\n      plot.caption = element_text(\n        hjust = 1, \n        size = base_size * 0.8,\n        color = \"grey40\"\n      ),\n      \n      # Axis elements\n      axis.title = element_text(\n        face = \"bold\", \n        color = \"black\",\n        size = base_size * 1.1\n      ),\n      axis.title.x = element_text(\n        margin = margin(t = base_size * 0.5),\n        hjust = title_position\n      ),\n      axis.title.y = element_text(\n        margin = margin(r = base_size * 0.5),\n        angle = 90,\n        hjust = title_position\n      ),\n      axis.text = element_text(color = \"grey30\"),\n      axis.line = element_line(\n        color = border_color, \n        linewidth = 0.8\n      ),\n      \n      # Panel elements\n      panel.grid.major = element_line(\n        color = \"grey92\", \n        linewidth = 0.3\n      ),\n      panel.grid.minor = element_blank(),\n      panel.background = element_rect(fill = \"white\", color = NA),\n      panel.border = element_blank(),\n      \n      # Legend elements\n      legend.title = element_text(face = \"bold\"),\n      legend.background = element_rect(fill = \"white\", color = NA),\n      legend.key = element_rect(fill = \"white\", color = NA),\n      \n      # Plot elements\n      plot.background = element_rect(fill = \"white\", color = NA),\n      plot.margin = margin(base_size, base_size, base_size, base_size),\n      strip.background = element_rect(fill = \"grey95\", color = NA),\n      strip.text = element_text(face = \"bold\")\n    )\n}\n\n\n#df_summary=rstatix::get_summary_stats(df,type=\"full\")\n#df_summary"
  },
  {
    "objectID": "posts/actuary-in-nepal.html",
    "href": "posts/actuary-in-nepal.html",
    "title": "How to Become an Actuary in Nepal",
    "section": "",
    "text": "Your Actuarial Journey in Nepal: A Comprehensive Guide\nAre you aspiring to become an actuary in Nepal? This guide will walk you through the essential steps, requirements, and resources to kick start your actuarial career.\n\nUnderstanding the Actuarial Profession in Nepal\n\nIn Nepal, the actuarial profession is gaining significant importance, particularly with the Nepal Insurance Authority (NIA) mandating actuarial analysts across the insurance sector. This creates a growing demand for qualified actuaries and actuarial professionals.\nActuarial Analyst Requirements by Nepal Insurance Authority (NIA)\nThe NIA‚Äôs ‚ÄòGuideline Related to Actuary Appointment for Insurers, 2024 (BS 2081)‚Äô outlines the roles and qualifications for actuarial professionals. While the guideline primarily focuses on ‚ÄòAppointed Actuaries‚Äô (Fellows), it also defines ‚ÄòActuarial Analysts‚Äô as individuals working towards an Associateship designation from a recognized Actuarial Association, with exposure to actuarial work.\nKey takeaways from the NIA guideline regarding Actuarial Analysts:\n‚Ä¢ Definition: An Actuarial Analyst is a person working towards the Associateship designation from a recognized Actuarial Association, has exposure to actuarial work, and contributes to an organization.\n‚Ä¢ Role: They support the statutory duties of the Appointed Actuary.\n‚Ä¢ Professional Conduct: Actuarial Analysts are responsible for complying with the professional code of conduct set by the Actuarial Society of Nepal.\nThis indicates that pursuing professional actuarial papers is a crucial step for anyone looking to work as an actuarial analyst in Nepal.\n\nChoosing Your Professional Actuarial Institute\n\nTo become a recognized actuary, you need to pass a series of professional examinations conducted by international actuarial bodies. The NIA guideline recognizes the following actuarial associations:\n‚Ä¢ Institute and Faculty of Actuaries (IFoA), UK: A globally recognized professional body offering qualifications for actuaries. Their examinations cover a wide range of actuarial science topics.\n‚Ä¢ Institute of Actuaries of India (IAI): A statutory body in India regulating the actuarial profession. It offers examinations and professional qualifications for actuaries.\n‚Ä¢ Society of Actuaries (SOA), USA: The world‚Äôs largest actuarial professional organization, primarily focusing on life, health, and pension actuarial science. They offer various designations, including Associate (ASA) and Fellow (FSA).\n‚Ä¢ Casualty Actuarial Society (CAS): An actuarial organization focused exclusively on property and casualty (general) insurance risks. They offer designations for actuaries specializing in this field.\nEach institute has its own examination structure, syllabus, and membership requirements. It‚Äôs essential to research each one to determine which aligns best with your career aspirations and study preferences.\n\nEducational Background: Bachelor‚Äôs Degree\n\nWhile the NIA guideline doesn‚Äôt specify a particular bachelor‚Äôs degree, a strong foundation in mathematics, statistics, and related quantitative subjects is essential. A bachelor‚Äôs degree is a fundamental requirement for pursuing an actuarial career.\nRecommendation: Bachelor in Mathematical Sciences (Actuarial Science) at Tribhuvan University\nFor students in Nepal, the School of Mathematical Sciences (SMS) at Tribhuvan University (TU) offers a highly recommended Bachelor in Mathematical Sciences (B.Math.Sc.) program with a major in Actuarial Science.\nHere‚Äôs why this program is beneficial:\n‚Ä¢ Curriculum Alignment: The coursework is closely designed to help students prepare for and pass international actuarial examinations, particularly those of the SOA.\n‚Ä¢ SOA UCAP Accreditation: Tribhuvan University‚Äôs actuarial science program is recognized by the Society of Actuaries (SOA) under its Universities & Colleges with Actuarial Programs (UCAP) - Actuarial Collegiate (UCAP-AC) status. This means that certain courses within the program are recognized for Validation by Educational Experience (VEE) credits, which are a requirement for SOA‚Äôs Associateship and Fellowship designations. This can significantly reduce the number of professional exams you need to take.\n‚Ä¢ Industry Connections: The institute‚Äôs industry connections can be invaluable for students seeking their first internships, providing practical experience and networking opportunities.\n‚Ä¢ Future Accreditations: The university is actively working towards gaining accreditation from the Institute and Faculty of Actuaries (IFoA), UK, which would further benefit students pursuing IFoA qualifications.\nNext Steps\n\nChoose an Institute: Decide which professional actuarial institute (IFoA, IAI, SOA, or CAS) best suits your career goals.\nStart Studying: Begin preparing for the preliminary exams of your chosen institute. Many resources are available online, including study guides and practice exams.\nGain Experience: Look for internships or entry-level positions as an actuarial analyst to gain practical experience in the field.\n\nEmbarking on an actuarial journey requires dedication and a strong quantitative aptitude. With the right educational foundation and professional qualifications, you can build a successful and rewarding career in Nepal‚Äôs growing insurance and financial sectors."
  },
  {
    "objectID": "all-blogs.html",
    "href": "all-blogs.html",
    "title": "All Blog Posts",
    "section": "",
    "text": "Below you can find all blog posts published on Actuarial Reflections.\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nUnderstanding Experience Study\n\n\n\nactuarial science\n\nlife insurance\n\nnon-life insurance\n\n\n\n\n\n\n\n\n\nJun 26, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\n\n\n\n\n\n\n\nDecoding Personality: ML Models as Your Guide to Introverts vs.¬†Extroverts\n\n\n\ndata science\n\ndescriptive\n\nml\n\n\n\n\n\n\n\n\n\nMay 26, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Become an Actuary in Nepal\n\n\n\nActuary\n\nNepal\n\nCareer\n\n\n\n\n\n\n\n\n\nMay 20, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Risk\n\n\n\nactuarial science\n\nlife insurance\n\nnon-life insurance\n\nrisk\n\nrisk Managment\n\n\n\n\n\n\n\n\n\nApr 26, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/understanding risk.html",
    "href": "posts/understanding risk.html",
    "title": "Understanding Risk",
    "section": "",
    "text": "Risk is a part of everyday life, whether in business, projects, or personal decisions. In simple terms, risk is the chance that something unexpected or undesirable might happen, leading to negative consequences.\n\n\nWhen thinking about risk, there are two main questions to ask: - How likely is it to happen? (Probability) - How bad would it be if it happens? (Impact)\nManaging risk means understanding both how often something might go wrong and how serious it would be if it does.\n\n\n\nRisks can be grouped based on their likelihood and impact. Here are four common types, and how you can manage each:\n\n\n\nThese are unlikely to happen and wouldn‚Äôt cause much harm if they did.\nHow to manage: - Accept the risk. These are often so small they aren‚Äôt worth much attention. - Monitor just in case. Keep an eye on them to make sure nothing changes.\nExample: Occasionally running out of printer paper at the office.\n\n\n\n\nUnlikely to occur, but if they do, the consequences could be severe.\nHow to manage: - Prepare contingency plans. Develop a plan for what to do if the risk happens. - Transfer the risk. Use insurance or contracts to share the risk with others. - Monitor regularly. Review the situation in case the likelihood increases.\nExample: An earthquake or other natural disaster.\n\n\n\n\nThese happen often, but their effects are minor.\nHow to manage: - Reduce how often they happen. Improve processes, provide training, or maintain equipment. - Keep records. Monitor how often these risks occur to spot any trends.\nExample: Minor technical glitches or small delays in routine tasks.\n\n\n\n\nBoth likely to happen and would have major consequences.\nHow to manage: - Act immediately. Address these risks with urgency. - Implement strong controls. Set up barriers or protections to reduce both likelihood and impact. - Develop and test response plans. Be ready to act if the risk materializes. - Monitor closely. Regularly review your controls and plans.\nExample: Cyberattacks that could expose sensitive data.\n\n\n\n\n\n\n\n\nType of Risk\nExample\nHow to Manage\n\n\n\n\nMinor\nPrinter out of paper\nAccept, Monitor\n\n\nRare but Serious\nEarthquake\nPlan, Transfer, Monitor\n\n\nFrequent, Low-Impact\nSmall IT glitches\nReduce, Monitor\n\n\nCritical\nCyberattack/data breach\nAct, Control, Respond, Monitor\n\n\n\n\nTip:\nGood risk management means focusing your efforts on the most important risks‚Äîthose that could happen frequently or cause the most harm."
  },
  {
    "objectID": "posts/understanding risk.html#key-elements-of-risk",
    "href": "posts/understanding risk.html#key-elements-of-risk",
    "title": "Understanding Risk",
    "section": "",
    "text": "When thinking about risk, there are two main questions to ask: - How likely is it to happen? (Probability) - How bad would it be if it happens? (Impact)\nManaging risk means understanding both how often something might go wrong and how serious it would be if it does."
  },
  {
    "objectID": "posts/understanding risk.html#types-of-risk-and-how-to-manage-them",
    "href": "posts/understanding risk.html#types-of-risk-and-how-to-manage-them",
    "title": "Understanding Risk",
    "section": "",
    "text": "Risks can be grouped based on their likelihood and impact. Here are four common types, and how you can manage each:\n\n\n\nThese are unlikely to happen and wouldn‚Äôt cause much harm if they did.\nHow to manage: - Accept the risk. These are often so small they aren‚Äôt worth much attention. - Monitor just in case. Keep an eye on them to make sure nothing changes.\nExample: Occasionally running out of printer paper at the office.\n\n\n\n\nUnlikely to occur, but if they do, the consequences could be severe.\nHow to manage: - Prepare contingency plans. Develop a plan for what to do if the risk happens. - Transfer the risk. Use insurance or contracts to share the risk with others. - Monitor regularly. Review the situation in case the likelihood increases.\nExample: An earthquake or other natural disaster.\n\n\n\n\nThese happen often, but their effects are minor.\nHow to manage: - Reduce how often they happen. Improve processes, provide training, or maintain equipment. - Keep records. Monitor how often these risks occur to spot any trends.\nExample: Minor technical glitches or small delays in routine tasks.\n\n\n\n\nBoth likely to happen and would have major consequences.\nHow to manage: - Act immediately. Address these risks with urgency. - Implement strong controls. Set up barriers or protections to reduce both likelihood and impact. - Develop and test response plans. Be ready to act if the risk materializes. - Monitor closely. Regularly review your controls and plans.\nExample: Cyberattacks that could expose sensitive data."
  },
  {
    "objectID": "posts/understanding risk.html#summary-table",
    "href": "posts/understanding risk.html#summary-table",
    "title": "Understanding Risk",
    "section": "",
    "text": "Type of Risk\nExample\nHow to Manage\n\n\n\n\nMinor\nPrinter out of paper\nAccept, Monitor\n\n\nRare but Serious\nEarthquake\nPlan, Transfer, Monitor\n\n\nFrequent, Low-Impact\nSmall IT glitches\nReduce, Monitor\n\n\nCritical\nCyberattack/data breach\nAct, Control, Respond, Monitor\n\n\n\n\nTip:\nGood risk management means focusing your efforts on the most important risks‚Äîthose that could happen frequently or cause the most harm."
  },
  {
    "objectID": "posts/Understanding Experiance Study.html",
    "href": "posts/Understanding Experiance Study.html",
    "title": "Understanding Experience Study",
    "section": "",
    "text": "Based on the article by Matthew Dunscombe and Alexander Zaidlin\n\n\n\nThis document summarizes the key points from the article ‚ÄúExperience Studies ‚Äì Understanding the Past While Planning for the Future,‚Äù which explores the critical role of experience studies in actuarial science and modern insurance. Experience studies analyze actual versus expected insurance events (such as deaths, lapses, and claims) within defined populations. The process supports actuaries in understanding trends, identifying risk drivers, refining assumptions, and complying with evolving financial standards.\n\n\n\n\n\nüìä Foundational Role: Experience studies are fundamental to actuarial work, dating back to the 17th century.\nüîç Core Metric: The comparison of actual insurance events to expected figures produces the actual-to-expected (A/E) ratio.\nüõ†Ô∏è Seven-Step Process: Steps include data gathering, preparation, exposure calculation, actual/expected comparison, aggregation, analysis, validation, and reporting.\nüìà Trend Analysis: Identifying data trends and outliers is vital for setting accurate assumptions.\n‚öñÔ∏è Credibility and Adjustment: Credibility methods and manual adjustments help refine and stabilize results.\nüåç External Factors: External variables and incurred-but-not-reported (IBNR) claims add complexity and require expert judgment.\nüíª Technology: Tools like SQL Server and SAS enable large-scale, efficient experience studies in addition to traditional Excel-based approaches.\n\n\n\n\n\n\n\nExperience studies have shaped actuarial science for centuries‚Äîbeginning with Edmund Halley‚Äôs annuity analysis. Over time, these studies evolved from simple mortality tables to complex, data-driven models essential for modern pricing, reserving, and regulatory compliance.\n\n\n\nCareful selection between policy snapshot datasets and transactional records is critical. Snapshot datasets provide a static policy view, while transactional datasets offer granular, event-level insights. Collaboration with IT and claims departments is vital to ensure data quality, making data preparation the most labor-intensive step.\n\n\n\nCalculating exposure quantifies the risk period for insurance events, enabling actuaries to derive rates by count and by amount (the latter reflecting financial impact). The choice between calendar year and policy year studies affects how exposure is segmented and analyzed.\n\n\n\nThe main analytical output is the A/E ratio, which compares observed claims to expected figures (from industry tables or internal assumptions). This ratio highlights deviations, guiding assumption changes or further analysis.\n\n\n\nGrouping results (by gender, product, etc.) enables actionable insights. Credibility theory determines the statistical reliability of groupings and whether to use benchmarks or granular analysis. Advanced methods like generalized linear models (GLMs) and Bayesian approaches enhance credibility assessments.\n\n\n\nActuaries must apply judgment in adjusting outputs for volatility and external events. Peer review and stakeholder feedback ensure assumptions are robust. Trend analysis links changes to underwriting, economic shifts, or product mix, informing future projections.\n\n\n\nNon-core influences like regulatory changes and market conditions can distort results. IBNR and in-course-of-settlement (ICOS) claims create uncertainty, requiring careful estimation to avoid understating actual experience.\n\n\n\nModern tools (SQL Server, SAS, etc.) handle large volumes and complex calculations more efficiently than traditional spreadsheet tools, enabling faster and more reproducible analyses.\n\n\n\nRigorous validation (reconciliation, sampling, analytical review) ensures accuracy. Documentation of methodology, assumptions, and findings supports transparency and sound decision-making.\n\n\n\nEffective studies require coordination between actuaries, claims, underwriting, IT, and business units. This teamwork improves data accuracy, result interpretation, and agreement on adjustments.\n\n\n\n\n\nExperience studies are the empirical foundation of actuarial analysis. While the main concept‚Äîcomparing actual to expected events‚Äîis straightforward, practical implementation involves complex data preparation, nuanced exposure calculation, trend/outlier analysis, and expert judgment.\nKey aspects include: - Data Preparation: The most resource-intensive step, involving cleansing, linking, and validating from various sources. The chosen data structure influences study design and insights. - Exposure Measurement: Accurate measurement underpins rates and A/E ratios, revealing alignment or deviation from expectations. - Trend and Outlier Detection: Helps refine assumptions and uncover extraordinary events or data issues. - Credibility and Modeling: Sophisticated statistical techniques balance observed data with prior information. - Manual Adjustments: Required to smooth volatility and reflect external events‚Äîpeer-reviewed for transparency. - Handling External Factors: Considered through advanced statistical methods and judgment. - IBNR and ICOS: Properly estimating late or unsettled claims is essential for accuracy. - Technology: Modern platforms streamline large, complex studies, letting actuaries focus on interpretation. - Documentation & Validation: Ensures stakeholder confidence and future usability. - Collaboration: Critical for ensuring data accuracy and relevance of findings.\n\n\n\n\nExperience studies remain vital for pricing, reserving, and risk management in insurance. Their success hinges on robust data preparation, accurate measurement, sound statistical practice, effective technology, and strong cross-department collaboration. Comprehensive documentation and validation underpin credibility, ensuring that experience studies remain a cornerstone of informed, data-driven actuarial decision-making."
  },
  {
    "objectID": "posts/Understanding Experiance Study.html#overview",
    "href": "posts/Understanding Experiance Study.html#overview",
    "title": "Understanding Experience Study",
    "section": "",
    "text": "This document summarizes the key points from the article ‚ÄúExperience Studies ‚Äì Understanding the Past While Planning for the Future,‚Äù which explores the critical role of experience studies in actuarial science and modern insurance. Experience studies analyze actual versus expected insurance events (such as deaths, lapses, and claims) within defined populations. The process supports actuaries in understanding trends, identifying risk drivers, refining assumptions, and complying with evolving financial standards."
  },
  {
    "objectID": "posts/Understanding Experiance Study.html#highlights",
    "href": "posts/Understanding Experiance Study.html#highlights",
    "title": "Understanding Experience Study",
    "section": "",
    "text": "üìä Foundational Role: Experience studies are fundamental to actuarial work, dating back to the 17th century.\nüîç Core Metric: The comparison of actual insurance events to expected figures produces the actual-to-expected (A/E) ratio.\nüõ†Ô∏è Seven-Step Process: Steps include data gathering, preparation, exposure calculation, actual/expected comparison, aggregation, analysis, validation, and reporting.\nüìà Trend Analysis: Identifying data trends and outliers is vital for setting accurate assumptions.\n‚öñÔ∏è Credibility and Adjustment: Credibility methods and manual adjustments help refine and stabilize results.\nüåç External Factors: External variables and incurred-but-not-reported (IBNR) claims add complexity and require expert judgment.\nüíª Technology: Tools like SQL Server and SAS enable large-scale, efficient experience studies in addition to traditional Excel-based approaches."
  },
  {
    "objectID": "posts/Understanding Experiance Study.html#key-insights",
    "href": "posts/Understanding Experiance Study.html#key-insights",
    "title": "Understanding Experience Study",
    "section": "",
    "text": "Experience studies have shaped actuarial science for centuries‚Äîbeginning with Edmund Halley‚Äôs annuity analysis. Over time, these studies evolved from simple mortality tables to complex, data-driven models essential for modern pricing, reserving, and regulatory compliance.\n\n\n\nCareful selection between policy snapshot datasets and transactional records is critical. Snapshot datasets provide a static policy view, while transactional datasets offer granular, event-level insights. Collaboration with IT and claims departments is vital to ensure data quality, making data preparation the most labor-intensive step.\n\n\n\nCalculating exposure quantifies the risk period for insurance events, enabling actuaries to derive rates by count and by amount (the latter reflecting financial impact). The choice between calendar year and policy year studies affects how exposure is segmented and analyzed.\n\n\n\nThe main analytical output is the A/E ratio, which compares observed claims to expected figures (from industry tables or internal assumptions). This ratio highlights deviations, guiding assumption changes or further analysis.\n\n\n\nGrouping results (by gender, product, etc.) enables actionable insights. Credibility theory determines the statistical reliability of groupings and whether to use benchmarks or granular analysis. Advanced methods like generalized linear models (GLMs) and Bayesian approaches enhance credibility assessments.\n\n\n\nActuaries must apply judgment in adjusting outputs for volatility and external events. Peer review and stakeholder feedback ensure assumptions are robust. Trend analysis links changes to underwriting, economic shifts, or product mix, informing future projections.\n\n\n\nNon-core influences like regulatory changes and market conditions can distort results. IBNR and in-course-of-settlement (ICOS) claims create uncertainty, requiring careful estimation to avoid understating actual experience.\n\n\n\nModern tools (SQL Server, SAS, etc.) handle large volumes and complex calculations more efficiently than traditional spreadsheet tools, enabling faster and more reproducible analyses.\n\n\n\nRigorous validation (reconciliation, sampling, analytical review) ensures accuracy. Documentation of methodology, assumptions, and findings supports transparency and sound decision-making.\n\n\n\nEffective studies require coordination between actuaries, claims, underwriting, IT, and business units. This teamwork improves data accuracy, result interpretation, and agreement on adjustments."
  },
  {
    "objectID": "posts/Understanding Experiance Study.html#extended-discussion",
    "href": "posts/Understanding Experiance Study.html#extended-discussion",
    "title": "Understanding Experience Study",
    "section": "",
    "text": "Experience studies are the empirical foundation of actuarial analysis. While the main concept‚Äîcomparing actual to expected events‚Äîis straightforward, practical implementation involves complex data preparation, nuanced exposure calculation, trend/outlier analysis, and expert judgment.\nKey aspects include: - Data Preparation: The most resource-intensive step, involving cleansing, linking, and validating from various sources. The chosen data structure influences study design and insights. - Exposure Measurement: Accurate measurement underpins rates and A/E ratios, revealing alignment or deviation from expectations. - Trend and Outlier Detection: Helps refine assumptions and uncover extraordinary events or data issues. - Credibility and Modeling: Sophisticated statistical techniques balance observed data with prior information. - Manual Adjustments: Required to smooth volatility and reflect external events‚Äîpeer-reviewed for transparency. - Handling External Factors: Considered through advanced statistical methods and judgment. - IBNR and ICOS: Properly estimating late or unsettled claims is essential for accuracy. - Technology: Modern platforms streamline large, complex studies, letting actuaries focus on interpretation. - Documentation & Validation: Ensures stakeholder confidence and future usability. - Collaboration: Critical for ensuring data accuracy and relevance of findings."
  },
  {
    "objectID": "posts/Understanding Experiance Study.html#conclusion",
    "href": "posts/Understanding Experiance Study.html#conclusion",
    "title": "Understanding Experience Study",
    "section": "",
    "text": "Experience studies remain vital for pricing, reserving, and risk management in insurance. Their success hinges on robust data preparation, accurate measurement, sound statistical practice, effective technology, and strong cross-department collaboration. Comprehensive documentation and validation underpin credibility, ensuring that experience studies remain a cornerstone of informed, data-driven actuarial decision-making."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Actuarial-Reflections",
    "section": "",
    "text": "Krishna Shrestha\n\n\n\n\n\n\n&lt;a href=\"https://tenor.com/view/pikachu-pokemon-waving-wave-hi-gif-16091246\"&gt;Pikachu Pokemon Sticker&lt;/a&gt;\nfrom &lt;a href=\"https://tenor.com/search/pikachu-stickers\"&gt;Pikachu Stickers&lt;/a&gt;\n\n\n\n\n\n\nActuarial Reflections Personal blog by Krishna Shrestha ‚Äî sharing insights, tutorials, and reflections on actuarial science, data science, and professional growth. Explore the latest posts below!\n\n\n\n\n\n\n\n\n View All Blogs \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Experience Study\n\n\n\nactuarial science\n\nlife insurance\n\nnon-life insurance\n\n\n\n\n\n\n\n\n\nJun 26, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\n\n\n\n\n\n\n\nDecoding Personality: ML Models as Your Guide to Introverts vs.¬†Extroverts\n\n\n\ndata science\n\ndescriptive\n\nml\n\n\n\n\n\n\n\n\n\nMay 26, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Become an Actuary in Nepal\n\n\n\nActuary\n\nNepal\n\nCareer\n\n\n\n\n\n\n\n\n\nMay 20, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Risk\n\n\n\nactuarial science\n\nlife insurance\n\nnon-life insurance\n\nrisk\n\nrisk Managment\n\n\n\n\n\n\n\n\n\nApr 26, 2025\n\n\nKrishna Kumar Shrestha\n\n\n\n\n\nNo matching items"
  }
]